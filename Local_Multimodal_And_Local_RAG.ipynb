{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuacPJHesj3R"
      },
      "outputs": [],
      "source": [
        "# !pip install llama-index llama-index-vector-stores-faiss llama-index-embeddings-ollama llama-index-llms-ollama pypdf\n",
        "# uvx --with=jupyterlab,llama-index,llama-index-vector-stores-faiss,llama-index-embeddings-ollama,llama-index-llms-ollama,pypdf jupyter notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Request-Response API"
      ],
      "metadata": {
        "id": "P-6oQvmcp-W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama"
      ],
      "metadata": {
        "id": "A7mIUhc2GsLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Ollama(model=\"gpt-oss:20b\", base_url=\"localhost:11434\", request_timeout=60.0)\n",
        "\n",
        "response = llm.complete(\"What is the capital of France, and what is it known for?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "fUUNysOjlZUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.llms import ChatMessage, TextBlock, ImageBlock\n",
        "from llama_index.llms.ollama import Ollama"
      ],
      "metadata": {
        "id": "PIcKGu8isvzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Ollama(\n",
        "    model=\"gemma3:27b\",\n",
        "    base_url=\"localhost:11434\",\n",
        "    request_timeout=120.0\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    ChatMessage(\n",
        "        role=\"user\",\n",
        "        blocks=[\n",
        "            TextBlock(text=\"What do you see on the image?\"),\n",
        "            ImageBlock(path=\"Downloads/fur.jpg\"),\n",
        "        ],\n",
        "    ),\n",
        "]\n",
        "\n",
        "resp = llm.chat(messages)\n",
        "print(resp)"
      ],
      "metadata": {
        "id": "yzF6ayRrp8rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On-Laptop RAG"
      ],
      "metadata": {
        "id": "UroGKPWwqB4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.ollama import OllamaEmbedding\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core import Settings"
      ],
      "metadata": {
        "id": "TOs3ODgFpW56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing the global default\n",
        "llm = Ollama(model=\"gemma3:27b\", base_url=\"localhost:11434\", request_timeout=120.0)\n",
        "Settings.llm = llm\n",
        "\n",
        "ollama_embedding = OllamaEmbedding(\n",
        "    model_name=\"nomic-embed-text:latest\",\n",
        "    base_url=\"localhost:11434\",\n",
        ")\n",
        "Settings.embed_model = ollama_embedding"
      ],
      "metadata": {
        "id": "XWb9xVTHnKJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://privatewealth.goldmansachs.com/outlook/2025-isg-outlook.pdf"
      ],
      "metadata": {
        "id": "uhN9urbeqdGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"./\").load_data(\"how-vector-embeddings-work.md\")\n",
        "# index = VectorStoreIndex.from_documents(documents)\n",
        "# query_engine = index.as_query_engine()\n",
        "# response = query_engine.query(\"What is vector embeddings?\")\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "ra7D_fOxrbBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWDd0mpVFEnX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}